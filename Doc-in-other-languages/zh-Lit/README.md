<div class="center" align="center">
  <a href="#">
    <img alt="Py-Crawler-ICON" src="https://helloosdisk.wikidot.com/local--files/file:github/Pyc" width="100px">
  </a><br/>
  <img alt="Py-Crawler-ICON" src="https://helloosdisk.wikidot.com/local--files/file:github/pyctext.png" width="300px">
  <p>备维基点之页面</p>
  <img alt="" src="https://img.shields.io/github/license/HelloOSMe/Py-crawler">&nbsp;&nbsp;<img alt="" src="https://img.shields.io/github/v/release/HelloOSMe/Py-Crawler?include_prereleases">&nbsp;&nbsp;<img alt="" src="https://img.shields.io/github/stars/HelloOSMe/Py-crawler">
</div>

----------

## Wiki HTML代码存档（Py-crawler）

此所以创一爬虫之功,以尽wiki之页面,用于被灾之后网站静只读版本也。或不宜于复工,然为恢复页面资。

凡此诸Wikidot网站,所以防恶入虫,网站必有pages页面而后可也。

### **配置所需**
```
立页面于网站URL/pages,添 [[module Pages preview="true"]] 代码
```

### **虫程序安装**
请击侧栏`Releases`，为新版，择源码击之。

### **爬虫行**
* 行取PyCrawlerGUI.exe。
* URL输汝诸处，点击认之。
* 往视网站URL/pages页面下page X of X后一数(即后一也x)
* 令行输入区输此数【若填多之(置此数为X,X≠0),当输1至X HTML文(名为pages1~pagesX.html)然(X-1)与X同】,然后换行。
* 静待程序执行毕，有弹窗一提醒也。 (若得一页面数升取,则常也,序上所有链接)
* 成? 记得打包一文件夹,免教混淆。

### **反馈地址**
遇过与BUG? 来 [此](http://ld-private-website.wikidot.com/forum/c-7602918/pyc) 反馈,或来 [此](https://github.com/HelloOSMe/Py-crawler/issues) 反馈。

有新功之心,而不知其所反馈? 来[此](http://ld-private-website.wikidot.com/forum/t-15402049/pyc-1-1-0-1-9)反馈,或来 [此](https://github.com/HelloOSMe/Py-crawler/issues) 反馈。

你可以给我给技术助? 来 [此](http://ld-private-website.wikidot.com/forum/c-7602920/) 反馈,或来 [此](https://github.com/HelloOSMe/Py-crawler/fork) 拉取支修改也。

----------
```
Copyright (c) 2023 Py-crawler Dev Team
All Rights Reserved.

版权所有PYC团队
留中权利也。

The icon "Py-Crawler-worm" is made by hatoyama_kumiko and is applicable to CC-BY-SA-4.0 protocol.

The application made by RedPanda Dev-Cpp , Visual Basic 6.0 and Windows Notepad.
```
