<div class="center" align="center">
  <a href="#">
    <img alt="Py-Crawler-ICON" src="https://helloosdisk.wikidot.com/local--files/file:github/Pyc" width="100px">
  </a><br/>
  <img alt="Py-Crawler-ICON" src="https://helloosdisk.wikidot.com/local--files/file:github/pyctext.png" width="300px">
  <p>Sauvegarder votre wikidot</p>
  <img alt="" src="https://img.shields.io/github/license/HelloOSMe/Py-crawler">&nbsp;&nbsp;<img alt="" src="https://img.shields.io/github/v/release/HelloOSMe/Py-Crawler?include_prereleases">&nbsp;&nbsp;<img alt="" src="https://img.shields.io/github/stars/HelloOSMe/Py-crawler">
</div>

----------
## Archive de code HTML Wiki (Py-crawler)

Ceci est utilisé pour créer un projet de robot d’exploration qui explore toutes les pages présentes sur le wiki pour les versions statiques en lecture seule du site Web après le sinistre. Il peut ne pas convenir à la restauration du projet, mais fournit une base pour la page de restauration.
Actuellement, cela s’applique à tous les sites Wikidot, mais pour empêcher les robots malveillants, tout site doit avoir une page de pages à explorer.


### **Configuration requise**

```
Créez une page sur l’URL/les pages de votre site Web et ajoutez le code [[module Pages preview="true"]]
```

### **Installation du crawler**

Veuillez cliquer sur la dernière version affichée dans la barre latérale `releases` et sélectionner “source code” pour le télécharger.

### **Le robot s’exécute**
* exécution avec Bash à la racine du projet `./main`.

* entrez votre adresse Web à l'URL et passez à la ligne.

* allez voir l'URL de votre site Web / System: List - All - pages le numéro suivant de la page x de X (dans cet exemple, le X suivant)

* saisissez ce nombre dans pages [Si vous le remplissez plus (soit X, X ≠ 0), il affichera un fichier HTML de 1 à X (nommé pages1 ~ pagesx.html), mais (X - 1) et X sont identiques] et changez de ligne.

* attendez tranquillement que le programme soit terminé, il y aura une invite de fenêtre.

* C'est fait? N'oubliez pas de déplacer le dossier HTML pour éviter toute confusion.

### **Adresse de rétroaction**
VOUS AVEZ UNE ERREUR OU UN BUG ? Venez à [ici](https://github.com/HelloOSMe/Py-crawler/issues) commentaires.

Vous avez une idée pour une nouvelle fonctionnalité, mais vous ne savez pas où donner votre avis ? Venez à [ici](https://github.com/HelloOSMe/Py-crawler/issues) commentaires.

Pouvez-vous nous donner de l’aide technique? Venez à [ici](https://github.com/HelloOSMe/Py-crawler/fork) tirez des branches pour apporter des modifications.

----------

```
Copyright (c) 2022-2023 HelloOSMe
All Rights Reserved.

Copyright (c) 2023 2022-2023 HelloOSMe
Tous droits réservés.

The Application for Linux made par redpanda dev - CPP, replit et Windows Notepad.
```
