<div class="center" align="center">
  <a href="#">
    <img alt="Py-Crawler-ICON" src="https://helloosdisk.wikidot.com/local--files/file:github/Pyc" width="100px">
  </a><br/>
  <img alt="Py-Crawler-ICON" src="https://helloosdisk.wikidot.com/local--files/file:github/pyctext.png" width="300px">
  <p>Sauvegarder votre wikidot</p>
  <img alt="" src="https://img.shields.io/github/license/HelloOSMe/Py-crawler">&nbsp;&nbsp;<img alt="" src="https://img.shields.io/github/v/release/HelloOSMe/Py-Crawler?include_prereleases">&nbsp;&nbsp;<img alt="" src="https://img.shields.io/github/stars/HelloOSMe/Py-crawler">
</div>

----------
## Archive de code HTML Wiki (Py-crawler)

Ceci est utilisé pour créer un projet de robot d’exploration qui explore toutes les pages présentes sur le wiki pour les versions statiques en lecture seule du site Web après le sinistre. Il peut ne pas convenir à la restauration du projet, mais fournit une base pour la page de restauration.
Actuellement, cela s’applique à tous les sites Wikidot, mais pour empêcher les robots malveillants, tout site doit avoir une page de pages à explorer.


### **Configuration requise**

```
Créez une page sur l’URL/les pages de votre site Web et ajoutez le code [[module Pages preview="true"]]
```

### **Installation du crawler**

Veuillez cliquer sur la dernière version affichée dans la barre latérale `releases` et sélectionner “source code” pour le télécharger.

### **Le robot s’exécute**
* pycrawlergui.exe est activé lors de l'exécution.

* entrez votre adresse Web à l'URL et appuyez sur confirmer.

* allez voir l'URL de votre site Web / System: List - All - pages le numéro suivant de la page x de X (dans cet exemple, le X suivant)

* saisissez ce nombre dans pages [Si vous le remplissez plus (soit X, X ≠ 0), il affichera un fichier HTML de 1 à X (nommé pages1 ~ pagesx.html), mais (X - 1) et X sont identiques] et changez de ligne.

* attendez tranquillement que le programme soit terminé, il y aura une invite de fenêtre.

* C'est fait? N'oubliez pas de déplacer le dossier HTML pour éviter toute confusion.

### **Captura de pantalla**
<img alt="" src="https://s1.ax1x.com/2023/02/20/pSXVpQJ.jpg" width="300px">  
<img alt="" src="https://s1.ax1x.com/2023/02/20/pSXExWF.jpg" width="300px">  
<img alt="" src="https://s1.ax1x.com/2023/02/20/pSXEzz4.jpg" width="300px">

### **Adresse de rétroaction**
VOUS AVEZ UNE ERREUR OU UN BUG ? Venez à [ici](http://ld-private-website.wikidot.com/forum/c-7602918/pyc) commentaires, ou venez [ici](https://github.com/HelloOSMe/Py-crawler/issues) commentaires.

Vous avez une idée pour une nouvelle fonctionnalité, mais vous ne savez pas où donner votre avis ? Venez à [ici](http://ld-private-website.wikidot.com/forum/t-15402049/pyc-1-1-0-1-9) commentaires, ou venez [ici](https://github.com/HelloOSMe/Py-crawler/issues) commentaires.

Pouvez-vous nous donner de l’aide technique? Venez à [ici](http://ld-private-website.wikidot.com/forum/c-7602920/) commentaires, ou [ici](https://github.com/HelloOSMe/Py-crawler/fork) tirez des branches pour apporter des modifications.

----------

```
Copyright (c) 2023 Py-crawler Dev Team
All Rights Reserved.

Copyright (c) 2023 Py-crawler Dev Team
Tous droits réservés.

L'icon "Py - crawler - Worm" est fait par Hatoyama Kumiko et son application au Protocole CC-by-sa-4.0.

L'application a été créée par redpanda dev - CPP, Visual Basic 6.0 et Windows Notepad.
```
