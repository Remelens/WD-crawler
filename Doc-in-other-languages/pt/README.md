<div class="center" align="center">
  <a href="#">
    <img alt="Py-Crawler-ICON" src="https://helloosdisk.wikidot.com/local--files/file:github/Pyc" width="100px">
  </a><br/>
  <img alt="Py-Crawler-ICON" src="https://helloosdisk.wikidot.com/local--files/file:github/pyctext.png" width="300px">
  <p>Fazer backup do seu wikidot</p>
  <img alt="" src="https://img.shields.io/github/license/HelloOSMe/Py-crawler">&nbsp;&nbsp;<img alt="" src="https://img.shields.io/github/v/release/HelloOSMe/Py-Crawler?include_prereleases">&nbsp;&nbsp;<img alt="" src="https://img.shields.io/github/stars/HelloOSMe/Py-crawler">
</div>

----------------

## Arquivo de código Wiki HTML (Py-crawler)

Isto é usado para criar um projeto crawler que rasteja todas as páginas que existem no wiki para leitura estática - apenas versão do site após o desastre. 
Pode não se aplicar ao projecto de recuperação, mas fornece uma base para restaurar a página. 

Por agora, isto aplica-se a todos os sites da Wikidot, mas para prevenir rastejadores maliciosos, qualquer site deve ter uma página para escalar.

### **Requisitos de configuração**

```
Crie uma página no URL/páginas do seu site e adicione [[module Pages preview="true"]] código
```

### **Instalação do rastreador**

Por favor, clique na versão mais recente exibida na barra lateral 'Releases' e selecione "Source Code" para baixar.

### **O rastejador corre**
* Use bash para executar no diretório raiz do projeto durante o tempo de execução `./main`.
* Digite o endereço do seu site na URL e execute-o como uma nova linha.
* Vá para verificar o próximo número de página X de X (neste exemplo, o próximo x) exibido sob o URL/sistema: list-all-pages page do seu site
* Digite este número nas páginas [se você preencher mais de um (defina este número como X, X ≠ 0), ele irá produzir 1~X arquivos HTML (nome: pages1~pagesX. html), mas (X-1) e X são os mesmos], e então wrap.
* Aguarde silenciosamente até que o programa termine a execução. Haverá um prompt pop-up.
* Terminado? Lembre-se de mover a pasta html para evitar confusão.

### **Endereço de feedback**
TEM UM ERRO OU ESCUTA? Venha para o feedback [aqui](https://github.com/HelloOSMe/Py-crawler/issues) feedback.

Tem uma ideia para uma nova funcionalidade, mas não sabe onde dar feedback? Venha para o feedback [aqui](https://github.com/HelloOSMe/Py-crawler/issues) feedback.

Pode dar-nos ajuda técnica? Venha para o feedback [aqui](https://github.com/HelloOSMe/Py-crawler/fork) puxe ramos para fazer alterações.

----------

```
Copyright (c) 2022-2023 HelloOSMe
All Rights Reserved.

Copyright (c) 2022-2023 HelloOSMe
Todos os direitos reservados.

A aplicação para Linux feita por RedPanda Dev-Cpp , Replit e Windows Notepad.
```
