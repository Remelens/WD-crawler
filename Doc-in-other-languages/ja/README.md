<div class="center" align="center">
  <a href="#">
    <img alt="Py-Crawler-ICON" src="https://helloosdisk.wikidot.com/local--files/file:github/Pyc" width="100px">
  </a><br/>
  <img alt="Py-Crawler-ICON" src="https://helloosdisk.wikidot.com/local--files/file:github/pyctext.png" width="300px">
  <p>あなたのwikidotをバックアップします</p>
  <img alt="" src="https://img.shields.io/github/license/HelloOSMe/Py-crawler">&nbsp;&nbsp;<img alt="" src="https://img.shields.io/github/v/release/HelloOSMe/Py-Crawler?include_prereleases">&nbsp;&nbsp;<img alt="" src="https://img.shields.io/github/stars/HelloOSMe/Py-crawler">
</div>

----------

## ウィキHTMLコードアーカイブ(Py-crawler)

これは、Wiki 上に存在するすべてのページをクロールするクローラ プロジェクトを作成し、被災後の Web サイトの静的読み取り専用バージョンに使用されます。 回復プロジェクトには適用されない場合がありますが、回復ページの基礎となります。
現時点では、これはすべてのWikidotサイトで動作しますが、悪意のあるクローラを防ぐために、任意のウェブサイトは、クロールする前にpagesページを持っている必要があります。

### **構成要件**
```
Web サイトの URL/pages にページを作成し、" [[module Pages preview="true"]] " コードを追加します
```

### **爬虫類プログラムのインストール**

サイドバー`Releases`に表示されている最新版をクリックし、「Source Code」を選択してダウンロードしてください。

### **爬虫類運転**
* 実行時にPyCrawlerGUI.exeを有効にします。
* URLにあなたのURLを入力し、確認をクリックします。
* あなたのウェブサイトURL/system：list-all-pagesページの下に表示されているpage X of Xの後ろの数を見てください（この例では後ろのxです）
* pagesにこの数を入力して（この数をX、X≠0とする）、1～XのHTMLファイル（pages 1～pagesX.htmlという名前）を出力しますが（X-1）とXは同じです）、改行します。
* プログラムが実行されるのを静かに待ちましょう。ポップアップが表示されます。
* 完了しましたか？htmlフォルダを混同しないように移動してください。

### **スクリーンショット**
<img alt="" src="https://s1.ax1x.com/2023/02/20/pSXVpQJ.jpg" width="300px">  
<img alt="" src="https://s1.ax1x.com/2023/02/20/pSXExWF.jpg" width="300px">  
<img alt="" src="https://s1.ax1x.com/2023/02/20/pSXEzz4.jpg" width="300px">

### **フィードバック アドレス**
エラーまたはバグが発生しましたか? [ここ](https://github.com/HelloOSMe/Py-crawler/issues)!

新機能のアイデアがありますが、フィードバックがわからない? [ここ](https://github.com/HelloOSMe/Py-crawler/issues)フィードバックに来てください。

あなたは私たちに技術的な助けを与えることができますか? [ここ](https://github.com/HelloOSMe/Py-crawler/fork)に来て、ブランチを引っ張って修正してください。

----------
```
Copyright (c) 2022-2023 HelloOSMe
All Rights Reserved.

著作権所有 (c) 2022-2023 HelloOSMe
すべての権利を保持します。

アイコン「Py Crawlerワーム」は、CC-by-SA-4.0プロトコルに適したhatoyama _ kumikoによって作成されています。

このアプリケーションは、RedPanda Dev Cpp、Visual Basic 6.0、Windowsメモ帳から作成されます。
```
